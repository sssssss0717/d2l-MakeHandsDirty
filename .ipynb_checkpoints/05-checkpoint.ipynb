{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b345e85e-b62b-4f3b-88ae-a5e2d5d26324",
   "metadata": {},
   "source": [
    "# 线性代数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6000b226-5d57-4569-9c1b-4e75c7d783c5",
   "metadata": {},
   "source": [
    "## 线性代数的实现\n",
    "标量由只有一个元素的张量表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0d9ceb5-12aa-4d00-aa77-bd70212ee51a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5.]), tensor([6.]), tensor([1.5000]), tensor([9.]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([3.0])\n",
    "y = torch.tensor([2.0])\n",
    "\n",
    "x + y, x * y, x / y, x ** y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070c196b-3ad0-4f6b-8d3d-d158fc1de03a",
   "metadata": {},
   "source": [
    "你可以将向量视为标量组成的列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f223b9a-5cf2-4258-b56b-65ea6fb05061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cf7fed-8cf5-4072-bdf9-c761bae8b7da",
   "metadata": {},
   "source": [
    "通过张量的索引来访问任一元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6c48aa4-c3f3-40e6-a1b7-57f8ba5d6cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82524f7-f871-4eae-9a62-c91d718cf4dd",
   "metadata": {},
   "source": [
    "访问张量的长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0340a76f-c326-4491-9d40-3467dc7fb06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efea9ec-7f9b-499b-9dde-9c4ae6a4c341",
   "metadata": {},
   "source": [
    "只有一个轴的张量，形状只有一个元素。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32cc9a72-698b-4e58-a748-c69dc1237823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5be1ab-bf5b-4116-8398-f94f3c91cc26",
   "metadata": {},
   "source": [
    "通过指定两个分量$m$和$n$来创建一个形状为$m×n$的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "488a622e-8f6e-4c1a-89bb-6c627e33476f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15],\n",
       "        [16, 17, 18, 19]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20).reshape(5,4)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86888505-54f4-4b41-9378-3594b1279ea1",
   "metadata": {},
   "source": [
    "矩阵的转置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b3986df-1152-48f9-8685-010daf8432b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  4,  8, 12, 16],\n",
       "        [ 1,  5,  9, 13, 17],\n",
       "        [ 2,  6, 10, 14, 18],\n",
       "        [ 3,  7, 11, 15, 19]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c7abbf-4171-491c-9952-6cfc1d937a75",
   "metadata": {},
   "source": [
    "*对称矩阵*(symmetric matrix)$A$等于其转置:$A = A^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "206e611a-4604-488c-9acb-a8e6821d1bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [2, 0, 4],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.tensor([[1, 2, 3], [2, 0, 4],[3, 4, 5]])\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9123d877-d2f0-4753-98a0-06b4354aabed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B == B.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81a0cb4-4080-4eb9-9141-5e7740259ffc",
   "metadata": {},
   "source": [
    "就像向量是标量的推广，矩阵是向量的推广一样，我们可以构建具有更多轴的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa9f19c0-00ec-40a8-9e43-120bcb0b46c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(24).reshape(2, 3, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea9404fb-a59e-4527-972c-b7b03d009b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor([[ 0.,  2.,  4.,  6.],\n",
       "         [ 8., 10., 12., 14.],\n",
       "         [16., 18., 20., 22.],\n",
       "         [24., 26., 28., 30.],\n",
       "         [32., 34., 36., 38.]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20, dtype = torch.float32).reshape(5,4)\n",
    "B = A.clone()  # 通过分配新内存，将A的一个副本分配给B\n",
    "A, A + B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7971177-3f82-4693-9dd2-223584b4f5cf",
   "metadata": {},
   "source": [
    "两个矩阵按元素乘法称为*哈达玛积*（Hadamard product) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b282e78-35f5-4045-86de-4fa577db2804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   1.,   4.,   9.],\n",
       "        [ 16.,  25.,  36.,  49.],\n",
       "        [ 64.,  81., 100., 121.],\n",
       "        [144., 169., 196., 225.],\n",
       "        [256., 289., 324., 361.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A * B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2df66604-e2d2-4dbf-873e-3552579afa74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 2,  3,  4,  5],\n",
       "          [ 6,  7,  8,  9],\n",
       "          [10, 11, 12, 13]],\n",
       " \n",
       "         [[14, 15, 16, 17],\n",
       "          [18, 19, 20, 21],\n",
       "          [22, 23, 24, 25]]]),\n",
       " torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 2\n",
    "X = torch.arange(24).reshape(2, 3, 4)\n",
    "a + X, (a * X).shape  #每个元素加a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07788aa6-4afd-4be9-ac5d-5700d8a46f0a",
   "metadata": {},
   "source": [
    "计算元素的和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0adc72a-918e-4190-bc26-cf37c6cc344f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), tensor(6.))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4, dtype = torch.float32)\n",
    "x, x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51176e3-c3ad-473b-a90e-039af4a0a29a",
   "metadata": {},
   "source": [
    "表示任意形状张量的元素和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d25bdd60-53ea-4403-8fe3-3f81c78712e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 4]), tensor(190))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20).reshape(5, 4)\n",
    "A.shape, A.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d29b105-c002-4d27-9352-b1b1d4f14615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0,  1,  2,  3],\n",
       "          [ 4,  5,  6,  7],\n",
       "          [ 8,  9, 10, 11],\n",
       "          [12, 13, 14, 15],\n",
       "          [16, 17, 18, 19]],\n",
       " \n",
       "         [[20, 21, 22, 23],\n",
       "          [24, 25, 26, 27],\n",
       "          [28, 29, 30, 31],\n",
       "          [32, 33, 34, 35],\n",
       "          [36, 37, 38, 39]]]),\n",
       " torch.Size([2, 5, 4]),\n",
       " tensor(780))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(2 * 20).reshape(2, 5, 4)\n",
    "A, A.shape, A.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de4f8308-29a7-471e-8fcb-44e16cddf524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15],\n",
       "        [16, 17, 18, 19]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A= torch.arange(20).reshape(5, 4)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843b1cbe-1ccd-43a2-a3e7-1a1ad101de11",
   "metadata": {},
   "source": [
    "指定求和汇总张量的轴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84138df3-d358-4195-96a9-7d9466d3d250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([40, 45, 50, 55]), torch.Size([4]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_sum_axis0 = A.sum(axis = 0)\n",
    "A_sum_axis0, A_sum_axis0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f504397-6305-42cf-a191-031024e39c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 6, 22, 38, 54, 70]), torch.Size([5]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_sum_axis1 = A.sum(axis = 1)\n",
    "A_sum_axis1, A_sum_axis1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70e77c6c-0476-4c9c-ae0a-1864b7f2e7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(190)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(axis = [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868b3c06-f427-40f4-b39d-1c00a7d5aaaa",
   "metadata": {},
   "source": [
    "axis = n, 就消灭第n个维度（求和）\n",
    "eg. axis = 1 (2, 5, 4)--(消灭“5”)-->(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b65e7aa-44d1-4588-adc1-d9763e9fbea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor(9.5000),\n",
       " tensor(9.5000))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = A.float()\n",
    "A, A.mean(), A.sum() / A.numel() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45d07d0-a028-494b-98d9-a9390112c9b7",
   "metadata": {},
   "source": [
    "一个与求和相关的量是*平均值*(mean or average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48a889c8-6ab6-4527-a774-68c82516be6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 8.,  9., 10., 11.]), tensor([ 8.,  9., 10., 11.]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(axis = 0), A.sum(axis = 0) / A.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9433aec7-acf0-44fc-9e33-5abc970cb032",
   "metadata": {},
   "source": [
    "计算总和或均值时保持轴数不变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f0e960e-334f-41fc-99c0-7b9dffd49cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.],\n",
       "        [22.],\n",
       "        [38.],\n",
       "        [54.],\n",
       "        [70.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_A = A.sum(axis = 1, keepdims = True)\n",
    "sum_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f097cf-d1e8-4355-bfd6-d77c06652e32",
   "metadata": {},
   "source": [
    "通过广播将`A`除以`sum_A`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4d04a0-3456-4705-9725-f5dcdc08bc13",
   "metadata": {},
   "source": [
    "A / sum_A\n",
    "这是逐行归一化（Row-wise normalization），\n",
    "对每一行的元素除以该行的总和，使得每一行的和为 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f346bcb5-79bf-424d-822d-636fc7b63ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  6.,  8., 10.],\n",
       "        [12., 15., 18., 21.],\n",
       "        [24., 28., 32., 36.],\n",
       "        [40., 45., 50., 55.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.cumsum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ccaa17-286b-4b3e-9d36-f0e50af12431",
   "metadata": {},
   "source": [
    "点积是相同位置的按元素乘积的和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6501e213-f3f8-4e72-90d6-19b582857c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]),\n",
       " tensor([1., 1., 1., 1.]),\n",
       " tensor([0., 1., 2., 3.]),\n",
       " tensor(6.))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.ones(4, dtype = torch.float32)\n",
    "x, y, x * y, torch.dot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca850654-265b-426d-b881-22926c321007",
   "metadata": {},
   "source": [
    "我们可以通过执行按元素乘法，然后进行求和来表示两个向量的点积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8abc227d-eaab-4497-ac7b-d89dd081ecd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(6.), tensor(6.))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(x * y), torch.dot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1f9338-ffdd-4d2f-851d-075a2428c7ff",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### ❗不同点总结：\n",
    "\n",
    "| 比较项             | `torch.dot(x, y)`               | `torch.sum(x * y)`                   |\n",
    "|------------------|-------------------------------|-------------------------------------|\n",
    "| 输入限制           | 只能用于 1D 向量                    | 任意形状（只要可广播）                    |\n",
    "| 计算类型           | 向量点积（数学定义）               | 广播后的逐元素乘积再求和                    |\n",
    "| 可读性             | 更清晰表达“点积”的意图              | 更通用，也可以用于矩阵或更高维度张量            |\n",
    "| 支持的维度         | 只能 1D                        | 支持任意维度（广播后乘法）                    |\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 推荐用法建议：\n",
    "- 如果明确知道 `x` 和 `y` 是一维向量，想计算点积，用 `torch.dot(x, y)`，可读性更强。\n",
    "- 如果 `x` 和 `y` 是多维张量，或你不确定维度，用 `torch.sum(x * y)` 更通用、更安全。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae413676-ba39-4906-a730-e19079da9e0e",
   "metadata": {},
   "source": [
    "矩阵向量积$Ax$是一个长度为$m$的列向量，其$i^{th}$元素是点积$a_i^Tx$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2b2ee37-34a7-47d9-81d2-f6b4100c2ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor([0., 1., 2., 3.]),\n",
       " torch.Size([5, 4]),\n",
       " torch.Size([4]),\n",
       " tensor([ 14.,  38.,  62.,  86., 110.]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, x, A.shape, x.shape, torch.mv(A, x)  #mv是matrix-vector（矩阵-向量）乘法的缩写。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc450c80-f5c3-46aa-991d-4e48904da617",
   "metadata": {},
   "source": [
    "我们可以将矩阵-矩阵乘法$AB$看作是简单地执行$m$次矩阵-向量积，并将结果拼接在一起，形成一个$n×m$矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a34ceb0b-dbd3-4d7f-817f-44c20d1752d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.,  6.,  6.],\n",
       "        [22., 22., 22.],\n",
       "        [38., 38., 38.],\n",
       "        [54., 54., 54.],\n",
       "        [70., 70., 70.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.ones(4, 3)\n",
    "torch.mm(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4ead2b-99d9-4021-9ca3-fc7ebe718153",
   "metadata": {},
   "source": [
    "$L_2$范数是向量元素平方和的平方根：\n",
    "$$\n",
    "||x||_2 = \\sqrt{\\sum_{i = 1}^{n}x_i^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55aefe88-1edb-42a3-b13b-eb48d1b2a823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.tensor([3.0, -4.0])\n",
    "torch.norm(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96cb9b3-b391-4e8f-80c0-095b1b36f012",
   "metadata": {},
   "source": [
    "$L_1$范数,它表示向量元素的绝对值之和：\n",
    "$$\n",
    "||x||_1 = \\sum_{i = 1}^{n}|x_i|\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe9a129f-812a-4ff9-85dd-81342308139c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(u).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86537faf-95a7-4a26-b64d-47c113b2e090",
   "metadata": {},
   "source": [
    "矩阵的*佛罗贝尼乌斯范数*(Forbenius norm)是矩阵元素的平方和的平方根：\n",
    "$$\n",
    "||x||_F = \\sqrt{\\sum_{i = 1}^{m}\\sum_{j = 1}^{n}x_i^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be675d05-18d2-496f-9527-ba062b988f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(torch.ones((4, 9)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7106430e-f291-4647-956d-a4e34ae58671",
   "metadata": {},
   "source": [
    "**从数学直观、几何意义、与代码实现**几个方面讲清楚它。\n",
    "\n",
    "---\n",
    "\n",
    "## 📘 一、什么是 Frobenius 范数？\n",
    "\n",
    "Frobenius 范数是一个 **衡量矩阵整体“大小”或“能量”** 的指标。\n",
    "\n",
    "它的定义类似于向量的 L2 范数，不过对象是一个 **矩阵**：\n",
    "\n",
    "$$\n",
    "\\|X\\|_F = \\sqrt{\\sum_{i=1}^{m}\\sum_{j=1}^{n} x_{ij}^2}\n",
    "$$\n",
    "\n",
    "就是说：**把矩阵中的每个元素平方，然后加起来，最后开根号。**\n",
    "\n",
    "---\n",
    "\n",
    "## 📐 二、几何意义（类比向量长度）\n",
    "\n",
    "- 对向量：\n",
    "$$\n",
    "  \\|u\\|_2 = \\sqrt{u_1^2 + u_2^2 + \\cdots + u_n^2}\n",
    "$$\n",
    "  —— 就是向量的“长度”。\n",
    "\n",
    "- 对矩阵：\n",
    "$$\n",
    "  \\|X\\|_F = \\sqrt{\\text{全部元素的平方和}}\n",
    "$$\n",
    "  —— 可以理解为把矩阵**“铺平”成一个长向量**后，求这个长向量的长度。\n",
    "\n",
    "👉 **所以 Frobenius 范数其实就是把矩阵看成一个大向量，计算它的 L2 范数。**\n",
    "\n",
    "---\n",
    "\n",
    "## 🧮 三、例子演算\n",
    "\n",
    "比如我们有一个矩阵：\n",
    "\n",
    "```python\n",
    "X = torch.tensor([[1.0, 2.0],\n",
    "                  [3.0, 4.0]])\n",
    "```\n",
    "\n",
    "那 Frobenius 范数是：\n",
    "$$\n",
    "\\|X\\|_F = \\sqrt{1^2 + 2^2 + 3^2 + 4^2} = \\sqrt{1 + 4 + 9 + 16} = \\sqrt{30} ≈ 5.4772\n",
    "$$\n",
    "在 PyTorch 中计算：\n",
    "```python\n",
    "torch.norm(X)  # 默认就是 Frobenius 范数\n",
    "```\n",
    "\n",
    "输出：\n",
    "```python\n",
    "tensor(5.4772)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ 四、在 PyTorch 中的使用方式\n",
    "\n",
    "```python\n",
    "X = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "\n",
    "torch.norm(X)               # 默认：Frobenius范数\n",
    "torch.norm(X, p='fro')      # 明确指定 Frobenius 范数\n",
    "torch.norm(X, p=2)          # 注意：对矩阵，p=2 会变成“谱范数”（最大奇异值），不一样\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 总结：\n",
    "\n",
    "| 项目                 | 含义                                  |\n",
    "|----------------------|---------------------------------------|\n",
    "| Frobenius范数         | 矩阵所有元素平方和的平方根              |\n",
    "| 几何意义             | 把矩阵当作“扁平向量”，求它的长度         |\n",
    "| PyTorch 默认行为     | `torch.norm(matrix)` 默认是 Frobenius范数 |\n",
    "| 与谱范数的区别        | `p=2` 对向量是 L2 范数，对矩阵是谱范数，不是 Frobenius 范数 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9e395d-e4bb-4cba-8a5e-d6f287947d67",
   "metadata": {},
   "source": [
    "## 按特定轴求和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3afa4763-1f19-4a44-b7ec-c217a97179f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.]]]),\n",
       " torch.Size([2, 5, 4]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.ones((2, 5, 4))\n",
    "a, a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d9a43ed-98e8-44cd-9fa1-6441f5c02f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sum().shape  #shape为空，表示他是标量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1e1bffe2-8e42-4de5-a714-dfe81a64f385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 5., 5., 5.],\n",
       "         [5., 5., 5., 5.]]),\n",
       " torch.Size([2, 4]),\n",
       " tensor([[[5., 5., 5., 5.]],\n",
       " \n",
       "         [[5., 5., 5., 5.]]]),\n",
       " torch.Size([2, 1, 4]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sum(axis = 1), a.sum(axis = 1).shape,a.sum(axis = 1, keepdims = True), a.sum(axis = 1, keepdims = True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f57a82-b050-4f7f-a432-c200e275e641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401ea526-32e8-463d-81b1-6e1353859a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686f90d4-0a59-497c-b310-e4e36bd26132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b99d71-2941-443d-916c-0eb4980a0e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b98dfba-c7d1-4d06-9a91-3bd88231ad0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad931d83-4124-4119-9ffe-ba84b84d58b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640aadd7-d3cc-4258-9514-0b2ee5e89f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110b69f0-9726-4c83-8fe8-7828d63aa003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72b2c04-cc17-4ce1-ab74-ba871643b5f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1606782-deda-4b3c-a56f-aa3f9b605000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057089c3-6557-4d91-8de3-6b0921b71056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5af0ada-37b2-4b18-a737-2b45e05c4acc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d25711-4957-4101-8d90-827326861f29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486893cf-8849-4eec-9046-adb07c23f471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048a7030-396f-4c9a-9d9d-5c0da6343fef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8edb6d-ed5d-4911-b0f7-4c9ebb0b6f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc19a3ce-380e-4dae-97dc-d16eb60071b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c2516f-6b0d-4b43-ad1c-ee118b457fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a795844-03cb-4152-b0e7-15dec2fcf633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d817ad2-5b2b-4ff4-b8de-b87c03f8b188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d068e9-4088-44bb-b63b-ce09b0bd296e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd21be0-589b-42c9-b8f9-a8f0788c6d31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d361a4-e2d1-46e8-b0f2-c4f9b521b3c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40722210-b846-4188-aaa7-fc43dd6c4d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e360cf-4b81-4923-a285-485e7ba92b17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
